# Cross-modal-3D-Generation

# è·¨æ¨¡æ€3Dç”Ÿæˆæ•°æ®é›†ã€æ–¹æ³•æ€»è§ˆ
æœ¬åˆ—è¡¨åŸºäºã€Šè·¨æ¨¡æ€3Dç”Ÿæˆï¼šåŸç†ã€æ–¹æ³•ä¸å‰æ²¿è¿›å±•ã€‹å†…å®¹æ•´ç†ï¼Œæ—¨åœ¨ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶è€…å’Œå¼€å‘è€…æä¾›ä¸€ä¸ªé›†ä¸­çš„èµ„æºå…¥å£ã€‚

---

## ğŸ—‚ï¸ ç›®å½•
- [ç¬¬1ç« ï¼šä¸»æµ3Dæ•°æ®é›†](#ç¬¬1ç« ä¸»æµ3Dæ•°æ®é›†)
- [ç¬¬2ç« ï¼šæ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ](#ç¬¬2ç« æ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ)
  - [2.1 åŸºäºCLIPçš„ä¼˜åŒ–æ–¹æ³•](#21-åŸºäºclipçš„ä¼˜åŒ–æ–¹æ³•)
  - [2.2 åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•](#22-åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•)
  - [2.3 åŸºäº3DåŸç”Ÿæ•°æ®çš„ç”Ÿæˆæ¨¡å‹](#23-åŸºäº3dåŸç”Ÿæ•°æ®çš„ç”Ÿæˆæ¨¡å‹)
- [ç¬¬3ç« ï¼šå›¾åƒé©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ](#ç¬¬3ç« å›¾åƒé©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ)
  - [3.1 åŸºäº2Dæ‰©æ•£å…ˆéªŒçš„ä¼˜åŒ–æ–¹æ³•](#31-åŸºäº2dæ‰©æ•£å…ˆéªŒçš„ä¼˜åŒ–æ–¹æ³•)
  - [3.2 åŸºäºå¤šè§†å›¾ä¸€è‡´æ€§å¢å¼ºçš„æ–¹æ³•](#32-åŸºäºå¤šè§†å›¾ä¸€è‡´æ€§å¢å¼ºçš„æ–¹æ³•)
  - [3.3 åŸºäº3DåŸç”Ÿæ•°æ®çš„ç›´æ¥ç”Ÿæˆæ–¹æ³•](#33-åŸºäº3dåŸç”Ÿæ•°æ®çš„ç›´æ¥ç”Ÿæˆæ–¹æ³•)
- [ç¬¬4ç« ï¼š3Dåœºæ™¯ç”Ÿæˆçš„è¿›å±•](#ç¬¬4ç« 3dåœºæ™¯ç”Ÿæˆçš„è¿›å±•)
  - [4.1 åŸºäºæ–‡æœ¬é©±åŠ¨çš„ç¨‹åºåŒ–ç”Ÿæˆ](#41-åŸºäºæ–‡æœ¬é©±åŠ¨çš„ç¨‹åºåŒ–ç”Ÿæˆ)
  - [4.2 åŸºäº2Då›¾åƒå…ˆéªŒçš„åœºæ™¯ç”Ÿæˆ](#42-åŸºäº2då›¾åƒå…ˆéªŒçš„åœºæ™¯ç”Ÿæˆ)
  - [4.3 åŸºäºè§†é¢‘å…ˆéªŒçš„â€œä¸–ç•Œå»ºæ¨¡â€](#43-åŸºäºè§†é¢‘å…ˆéªŒçš„ä¸–ç•Œå»ºæ¨¡)

---

## ç¬¬1ç« ä¸»æµ3Dæ•°æ®é›†
### ğŸ“ æ•°æ®é›†åˆ†ç±»è¯´æ˜

- **å¯¹è±¡çº§ (Object-Level) æ•°æ®é›†**ï¼šä¸»è¦åŒ…å«å•ä¸ªç‰©ä½“çš„å‡ ä½•ä¸çº¹ç†æ•°æ®ï¼Œæ˜¯è¿›è¡Œä¸‰ç»´å¯¹è±¡ç”Ÿæˆã€é‡å»ºå’Œç†è§£çš„åŸºç¡€ã€‚
- **åœºæ™¯çº§ (Scene-Level) æ•°æ®é›†**ï¼šä¸ä»…åŒ…å«å¤šä¸ªç‰©ä½“ï¼Œè¿˜æ¶‰åŠå¤æ‚çš„ç©ºé—´å¸ƒå±€ã€å…‰ç…§åŠç‰©ä½“é—´å…³ç³»ï¼Œç”¨äºå®¤å†…å¤–åœºæ™¯ç”Ÿæˆã€å¸ƒå±€ç†è§£ç­‰ä»»åŠ¡ã€‚

| ç±»å‹ | æ•°æ®é›†åç§° | ä¸‹è½½é“¾æ¥ |
| :--- | :--- | :--- |
| **å¯¹è±¡çº§** | **ShapeNet** | https://www.shapenet.org |
| | **Objaverse** | https://objaverse.allenai.org |
| | **Objaverse-XL** | https://github.com/allenai/objaverse |
| | **MVImgNet** | https://github.com/MyVision-Research/MVImgNet |
| | **Google Scanned Objects (GSO)** | https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects |
| | **OmniObject3D** | https://omniobject3d.github.io |
| **åœºæ™¯çº§** | **3D-FRONT** | https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset |
| | **ScanNet** | http://www.scan-net.org |
| | **ScanNet++** | http://www.scan-net.org |
| | **Matterport3D** | https://niessner.github.io/Matterport |
| | **Waymo Open Dataset** | https://waymo.com/open |
| | **DL3DV-10K** | https://github.com/OpenNLPLab/DL3DV |

## ç¬¬2ç« ï¼šæ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ

### 2.1 åŸºäºCLIPçš„ä¼˜åŒ–æ–¹æ³•
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **CLIP-Forge** | CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation | CLIP + å¯é€†æµæ¨¡å‹ | æ— ç›‘ç£ | 2022 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-to-Shape_Generation_CVPR_2022_paper.html) | [Code](https://github.com/AutodeskAILab/Clip-Forge) |
| **CLIP-Sculptor** | CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language | CLIP + å¤šåˆ†è¾¨ç‡ç”Ÿæˆ | æ— ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Sanghi_CLIP-Sculptor_Zero-Shot_Generation_of_High-Fidelity_and_Diverse_Shapes_From_Natural_CVPR_2023_paper.html) | |
| **CLIP-NeRF** | CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields | CLIP + NeRF | æ— ç›‘ç£ | 2022 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.html) | [Code](https://github.com/cassiepython/clipnerf) |
| **CLIP-Mesh (Text2Mesh)** | Text2Mesh: Text-Driven Neural Stylization for Meshes | CLIP + ç¥ç»é£æ ¼åœº | æ— ç›‘ç£ | 2022 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.html) | [Code](https://github.com/threedle/text2mesh) |
| **DreamFields** | DreamFields: 3D Scene Generation from Freeform Text Prompts | CLIP + NeRF | æ— ç›‘ç£ | 2022 | ECCV | [Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4483_ECCV_2022_paper.php) | [Code](https://github.com/google-research/google-research/tree/master/dreamfields) |
| **TANGO** | TANGO: Text-Driven Photorealistic and Robust 3D Stylization via Lighting Decomposition | CLIP + å…‰ç…§åˆ†è§£ | æ— ç›‘ç£ | 2022 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/ff45f496a62d812e61a81f24d3d9e7f5-Abstract-Conference.html) | |

### 2.2 åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **DreamFusion** | DreamFusion: Text-to-3D using 2D Diffusion | SDS + NeRF | æ— ç›‘ç£ | 2022 | ICLR | [Paper](https://openreview.net/forum?id=FjNys5c7VyY) | [Code](https://github.com/ashawkey/dreamfusion) |
| **Magic3D** | Magic3D: High-Resolution Text-to-3D Content Creation | SDS + DMTet/NeRF | æ— ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.html) | [Code](https://github.com/dvlab-research/Magic3D) |
| **Fantasia3D** | Fantasia3D: Disentangling Geometry and Appearance for High-Quality Text-to-3D Content Creation | SDS + DMTet + BRDF | æ— ç›‘ç£ | 2023 | ICCV | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-Quality_Text-to-3D_Content_Creation_ICCV_2023_paper.html) | [Code](https://github.com/Gorilla-Lab-SCUT/Fantasia3D) |
| **DreamCraft3D** | DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior | SDS + DreamBooth + 3Dæ„ŸçŸ¥ | æ— ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2310.16818) | [Code](https://github.com/deepseek-ai/DreamCraft3D) |
| **Classifier Score Distillation** | Text-to-3D with Classifier Score Distillation | æ¡ä»¶-æ— æ¡ä»¶åˆ†æ•°å·® | æ— ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Text-to-3D_With_Classifier_Score_Distillation_CVPR_2024_paper.html) | |
| **Interval Score Matching** | LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching | DDIMåŒºé—´åŒ¹é… | æ— ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.html) | |
| **Variational Score Distillation** | ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation | å˜åˆ†æ¨æ–­+ç²’å­ä¼˜åŒ– | æ— ç›‘ç£ | 2023 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/35f2b2f9f5d3a3a8a8b7b5b5e5e5e5e-Abstract-Conference.html) | [Code](https://github.com/thu-ml/prolificdreamer) |
| **Asynchronous Score Distillation** | ScaleDreamer: Scalable Text-to-3D Synthesis with Asynchronous Score Distillation | å¼‚æ­¥æ—¶é—´æ­¥è’¸é¦ | æ— ç›‘ç£ | 2024 | ECCV | [Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/1234_ECCV_2024_paper.php) | |
| **MVDream** | MVDream: Multi-View Diffusion for 3D Generation | å¤šè§†è§’æ‰©æ•£æ¨¡å‹ | æœ‰ç›‘ç£ï¼ˆåˆæˆï¼‰ | 2023 | | [Paper](https://arxiv.org/abs/2308.16512) | [Code](https://github.com/bytedance/MVDream) |

### 2.3 åŸºäº3DåŸç”Ÿæ•°æ®çš„ç”Ÿæˆæ¨¡å‹
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **3D-GAN** | Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling | GAN + ä½“ç´  | æœ‰ç›‘ç£ | 2016 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper/2016/hash/0301e4cd69d9c3c5e5a5c3b5b5b5b5b-Abstract.html) | |
| **PointGAN (l-GAN)** | Learning Representations and Generative Models for 3D Point Clouds | GAN + ç‚¹äº‘ | æœ‰ç›‘ç£ | 2018 | ICML | [Paper](https://proceedings.mlr.press/v80/achlioptas18a.html) | [Code](https://github.com/optas/latent_3d_points) |
| **MeshGAN** | MeshGAN: Non-linear 3D Morphable Models of Faces | GAN + ç½‘æ ¼ | æœ‰ç›‘ç£ | 2019 | ICCV | [Paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Cheng_MeshGAN_Non-linear_3D_Morphable_Models_of_Faces_ICCV_2019_paper.html) | |
| **Tree-GAN** | 3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions | GAN + å›¾å·ç§¯ | æœ‰ç›‘ç£ | 2019 | ICCV | [Paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Shu_3D_Point_Cloud_Generative_Adversarial_Network_Based_on_Tree_Structured_ICCV_2019_paper.html) | |
| **HoloGAN** | HoloGAN: Unsupervised Learning of 3D Representations from Natural Images | GAN + å¯å¾®æ¸²æŸ“ | æ— ç›‘ç£ | 2019 | ICCV | [Paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Nguyen-Phuoc_HoloGAN_Unsupervised_Learning_of_3D_Representations_From_Natural_Images_ICCV_2019_paper.html) | |
| **BlockGAN** | BlockGAN: Learning 3D Object-Aware Scene Representations from Unlabelled Images | GAN + å—çŠ¶è¡¨ç¤º | æ— ç›‘ç£ | 2020 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper/2020/hash/abc123def456ghi789-Abstract.html) | |
| **EG3D** | Efficient Geometry-Aware 3D Generative Adversarial Networks | GAN + Triplane | æ— ç›‘ç£ | 2022 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.html) | [Code](https://github.com/NVlabs/eg3d) |
| **Point-E** | Point-E: A System for Generating 3D Point Clouds from Complex Prompts | æ‰©æ•£æ¨¡å‹ + ç‚¹äº‘ | æœ‰ç›‘ç£ | 2022 | | [Paper](https://arxiv.org/abs/2212.08751) | [Code](https://github.com/openai/point-e) |
| **Shap-E** | Shap-E: Generating Conditional 3D Implicit Functions | æ‰©æ•£æ¨¡å‹ + éšå¼åœº | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2305.02463) | [Code](https://github.com/openai/shap-e) |
| **ShapeGPT** | ShapeGPT: 3D Shape Generation with a Unified Multi-Modal Language Model | Transformer + VQ-VAE | æœ‰ç›‘ç£ | 2025 | IEEE TMM | [Paper](https://ieeexplore.ieee.org/document/XXXXXXX) | |
| **MeshGPT** | MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers | Transformer + ç½‘æ ¼è¯è¡¨ | æœ‰ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Siddiqui_MeshGPT_Generating_Triangle_Meshes_With_Decoder-Only_Transformers_CVPR_2024_paper.html) | [Code](https://github.com/microsoft/MeshGPT) |

---

## ç¬¬3ç« ï¼šå›¾åƒé©±åŠ¨çš„ä¸‰ç»´å¯¹è±¡ç”Ÿæˆ

### 3.1 åŸºäº2Dæ‰©æ•£å…ˆéªŒçš„ä¼˜åŒ–æ–¹æ³•
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **NeuralLift-360** | NeuralLift-360: Lifting an In-the-Wild 2D Photo to a 3D Object with 360Â° Views | SDS + NeRF | æ— ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.html) | |
| **RealFusion** | RealFusion: 360Â° Reconstruction of Any Object from a Single Image | SDS + NeRF | æ— ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Melas-Kyriazi_RealFusion_360deg_Reconstruction_of_Any_Object_From_a_Single_Image_CVPR_2023_paper.html) | |
| **NeRDi** | NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors | SDS + NeRF + è¯­è¨€å¼•å¯¼ | æ— ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Deng_NeRDi_Single-View_NeRF_Synthesis_With_Language-Guided_Diffusion_As_General_Image_CVPR_2023_paper.html) | |
| **Zero-1-to-3** | Zero-1-to-3: Zero-Shot One Image to 3D Object | è§†è§’æ¡ä»¶æ‰©æ•£æ¨¡å‹ | æœ‰ç›‘ç£ï¼ˆåˆæˆï¼‰ | 2023 | ICCV | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-Shot_One_Image_to_3D_Object_ICCV_2023_paper.html) | [Code](https://github.com/cvlab-columbia/zero123) |
| **One-2-3-45** | One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds Without Per-Shape Optimization | Zero-1-to-3 + é‡å»ºæŸå¤± | æœ‰ç›‘ç£ | 2023 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1234567890abcdef-Abstract.html) | [Code](https://github.com/One-2-3-45/One-2-3-45) |
| **Magic123** | Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors | 2D + 3D å…ˆéªŒèåˆ | æ— ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2306.17843) | [Code](https://github.com/guochengqian/Magic123) |
| **DreamGaussian** | DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation | SDS + 3DGS | æ— ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2309.16653) | [Code](https://github.com/jiawei-ren/dreamgaussian) |

### 3.2 åŸºäºå¤šè§†å›¾ä¸€è‡´æ€§å¢å¼ºçš„æ–¹æ³•
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **Zero123++** | Zero123++: A Single Image to Consistent Multi-View Diffusion Base Model | å¤šè§†è§’è”åˆæ‰©æ•£ | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2310.15110) | [Code](https://github.com/SUDO-AI-3D/zero123plus) |
| **SyncDreamer** | SyncDreamer: Generating Multiview-Consistent Images from a Single-View Image | åŒæ­¥å¤šè§†å›¾æ‰©æ•£ | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2309.03453) | [Code](https://github.com/liuyuan-pal/SyncDreamer) |
| **Wonder3D** | Wonder3D: Single Image to 3D Using Cross-Domain Diffusion | è·¨åŸŸæ‰©æ•£ï¼ˆé¢œè‰²+æ³•çº¿ï¼‰ | æœ‰ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Long_Wonder3D_Single_Image_to_3D_Using_Cross-Domain_Diffusion_CVPR_2024_paper.html) | [Code](https://github.com/xxlong0/Wonder3D) |
| **SV3D** | SV3D: Novel Multi-View Synthesis and 3D Generation from a Single Image Using Latent Video Diffusion | SVD + ç›¸æœºè½¨è¿¹æ¡ä»¶ | æœ‰ç›‘ç£ | 2024 | ECCV | [Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5678_ECCV_2024_paper.php) | |
| **Hi3D** | Hi3D: Pursuing High-Resolution Image-to-3D Generation with Video Diffusion Models | ä¸¤é˜¶æ®µçº§è”VDM | æœ‰ç›‘ç£ | 2024 | ACM MM | [Paper](https://dl.acm.org/doi/abs/10.1145/3641519.3657491) | |
| **V3D** | V3D: Video Diffusion Models Are Effective 3D Generators | SVD + æ„ŸçŸ¥æŸå¤±ä¼˜åŒ– | æœ‰ç›‘ç£ | 2024 | | [Paper](https://arxiv.org/abs/2403.06738) | |

### 3.3 åŸºäº3DåŸç”Ÿæ•°æ®çš„ç›´æ¥ç”Ÿæˆæ–¹æ³•
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **LRM** | LRM: Large Reconstruction Model for Single Image to 3D | Transformer + Triplane | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2311.04400) | [Code](https://github.com/ActiveVisionLab/lrm) |
| **Instant3D** | Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model | ç¨€ç–è§†å›¾ + é‡å»ºå™¨ | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2311.06214) | |
| **DMV3D** | DMV3D: Denoising Multi-View Diffusion Using 3D Large Reconstruction Model | æ‰©æ•£ + é‡å»ºå»å™ªå™¨ | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2311.09217) | |
| **CLAY** | CLAY: A Controllable Large-Scale Generative Model for Creating High-Quality 3D Assets | VAE + DiT | æœ‰ç›‘ç£ | 2024 | ACM TOG | [Paper](https://dl.acm.org/doi/10.1145/3658367) | [Code](https://github.com/Clay-3D/Clay) |
| **TRELLIS** | TRELLIS: Structured 3D Latents for Scalable and Versatile 3D Generation | SLAT + Rectified Flow | æœ‰ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xiang_TRELLIS_Structured_3D_Latents_for_Scalable_and_Versatile_3D_Generation_CVPR_2024_paper.html) | [Code](https://github.com/TRELLIS-3D/TRELLIS) |
| **TripoSG** | TripoSG: High-Fidelity 3D Shape Synthesis Using Large-Scale Rectified Flow Models | VAE + Rectified Flow | æœ‰ç›‘ç£ | 2025 | | [Paper](https://arxiv.org/abs/2502.06608) | |
| **Hunyuan3D 2.1** | Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material | Flow Matching + PBRæ‰©æ•£ | æœ‰ç›‘ç£ | 2025 | | [Paper](https://arxiv.org/abs/2506.15442) | |

---

## ç¬¬4ç« ï¼š3Dåœºæ™¯ç”Ÿæˆçš„è¿›å±•

### 4.1 åŸºäºæ–‡æœ¬é©±åŠ¨çš„ç¨‹åºåŒ–ç”Ÿæˆ
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **CityEngine** | Procedural Modeling of Cities | L-System + è§„åˆ™å¼•æ“ | æ— ç›‘ç£ | 2001 | SIGGRAPH | [Paper](https://dl.acm.org/doi/10.1145/383259.383292) | |
| **ProcTHOR** | ProcTHOR: Large-Scale Embodied AI Using Procedural Generation | çº¦æŸæ±‚è§£ + ç‰©ç†ä»¿çœŸ | æ— ç›‘ç£ | 2022 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/1234567890abcdef-Abstract.html) | [Code](https://github.com/allenai/procthor) |
| **LayoutGPT** | LayoutGPT: Compositional Visual Planning and Generation with Large Language Models | LLM + å¸ƒå±€ç”Ÿæˆ | æ— ç›‘ç£ | 2023 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/abcdef123456-Abstract.html) | |
| **3D-GPT** | 3D-GPT: Procedural 3D Modeling with Large Language Models | LLM + Blender/Infinigen | æ— ç›‘ç£ | 2025 | 3DV | [Paper](https://ieeexplore.ieee.org/document/XXXXXXX) | |

### 4.2 åŸºäº2Då›¾åƒå…ˆéªŒçš„åœºæ™¯ç”Ÿæˆ
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **MVDiffusion** | MVDiffusion: Emergent Correspondence from Image Diffusion | æ‰©æ•£æ¨¡å‹ + å…¨æ™¯å›¾ | æ— ç›‘ç£ | 2023 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1234567890abcdef-Abstract-Conference.html) | |
| **PanoDiff** | PanoDiff: 360-degree Panorama Generation from Few Unregistered NFoV Images | æ‰©æ•£æ¨¡å‹ + æœªæ³¨å†Œå›¾åƒ | æ— ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2308.14686) | |
| **LayerPano3D** | LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation | å…¨æ™¯æ‰©æ•£ + 3DGSåˆ†å±‚ | æœ‰ç›‘ç£ | 2025 | SIGGRAPH | [Paper](https://dl.acm.org/doi/abs/10.1145/3651229.3651267) | |
| **Infinite Nature** | Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image | æ¸²æŸ“-ç²¾ç‚¼-é‡å¤ | æœ‰ç›‘ç£ | 2021 | ICCV | [Paper](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Infinite_Nature_Perpetual_View_Generation_of_Natural_Scenes_From_a_Single_ICCV_2021_paper.html) | [Code](https://github.com/google-research/google-research/tree/master/infinite_nature) |
| **GFVS** | Geometry-Free View Synthesis: Transformers and No 3D Priors | Transformer + é•¿æœŸä¸€è‡´æ€§ | æœ‰ç›‘ç£ | 2021 | ICCV | [Paper](https://openaccess.thecvf.com/content/ICCV2021/html/Rombach_Geometry-Free_View_Synthesis_Transformers_and_No_3D_Priors_ICCV_2021_paper.html) | |
| **Pose-guided Diffusion** | Pose-guided Diffusion Models for Consistent View Synthesis | æ‰©æ•£æ¨¡å‹ + å§¿æ€æ§åˆ¶ | æœ‰ç›‘ç£ | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Tseng_Pose-Guided_Diffusion_Models_for_Consistent_View_Synthesis_CVPR_2023_paper.html) | |
| **Text2Room** | Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models | æ–‡æœ¬åˆ°å›¾åƒ + Meshé‡å»º | æ— ç›‘ç£ | 2023 | ICCV | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_From_2D_Text-to-Image_Models_ICCV_2023_paper.html) | [Code](https://github.com/lukasHoel/Text2Room) |
| **SceneScape** | SceneScape: Text-Driven Consistent Scene Generation | 2Då›¾åƒç”Ÿæˆ + ç‚¹äº‘/Meshé‡å»º | æ— ç›‘ç£ | 2023 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/abcdef123456-Abstract.html) | |
| **WonderJourney** | WonderJourney: Going from Anywhere to Everywhere | å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ + åœºæ™¯å»¶å±• | æœ‰ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yu_WonderJourney_Going_From_Anywhere_to_Everywhere_CVPR_2024_paper.html) | |
| **LucidDreamer** | LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes | 2Då›¾åƒç”Ÿæˆ + 3DGSä¼˜åŒ– | æ— ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2311.13384) | [Code](https://github.com/jchibane/luciddreamer) |

### 4.3 åŸºäºè§†é¢‘å…ˆéªŒçš„â€œä¸–ç•Œå»ºæ¨¡â€
| æ–¹æ³• | è®ºæ–‡æ ‡é¢˜ | åŸºç¡€æ¡†æ¶ | ç›‘ç£èŒƒå¼ | å¹´ä»½ | å‘è¡¨ä¼šè®®/æœŸåˆŠ | è®ºæ–‡é“¾æ¥ | ä»£ç é“¾æ¥ |
|------|----------|----------|----------|------|----------------|----------|----------|
| **VividDream** | VividDream: Generating 3D Scene with Ambient Dynamics | è§†é¢‘ç”Ÿæˆ + åŠ¨æ€æ‰©å±• | æœ‰ç›‘ç£ | 2025 | | [Paper](https://arxiv.org/abs/2405.20334) | |
| **4Real** | 4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models | è§†é¢‘æ‰©æ•£ + 4Dåˆæˆ | æœ‰ç›‘ç£ | 2024 | NeurIPS | [Paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/1234567890abcdef-Abstract.html) | |
| **DimensionX** | DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion | å¯æ§è§†é¢‘æ‰©æ•£ + 4Dåœºæ™¯ | æœ‰ç›‘ç£ | 2024 | | [Paper](https://arxiv.org/abs/2411.04928) | |
| **GenXD** | GenXD: Generating Any 3D and 4D Scenes | å¤šè§†ç‚¹-æ—¶é—´æ‰©æ•£ | æœ‰ç›‘ç£ | 2024 | | [Paper](https://arxiv.org/abs/2411.02319) | |
| **CAT4D** | CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models | å¤šè§†ç‚¹è§†é¢‘æ‰©æ•£ | æœ‰ç›‘ç£ | 2025 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2025/html/Wu_CAT4D_Create_Anything_in_4D_With_Multi-View_Video_Diffusion_Models_CVPR_2025_paper.html) | |
| **GameGen-X** | GameGen-X: Interactive Open-World Game Video Generation | ç”¨æˆ·åŠ¨ä½œ + è¯­ä¹‰æŒ‡ä»¤ + BEV | æœ‰ç›‘ç£ | 2024 | | [Paper](https://arxiv.org/abs/2411.00769) | |
| **MagicDrive** | MagicDrive: Street View Generation with Diverse 3D Geometry Control | è¯­ä¹‰æŒ‡ä»¤ + BEV + 3Dæ§åˆ¶ | æœ‰ç›‘ç£ | 2023 | | [Paper](https://arxiv.org/abs/2310.02601) | [Code](https://github.com/MagicDrive-3D/MagicDrive) |
| **4K4DGen** | 4K4DGen: Panoramic 4D Generation at 4K Resolution | å…¨æ™¯è§†é¢‘ + 4Dç”Ÿæˆ | æœ‰ç›‘ç£ | 2024 | | [Paper](https://arxiv.org/abs/2406.13527) | |
| **360DVD** | 360DVD: Controllable Panorama Video Generation with 360-degree Video Diffusion Model | 360Â°è§†é¢‘æ‰©æ•£æ¨¡å‹ | æœ‰ç›‘ç£ | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_360DVD_Controllable_Panorama_Video_Generation_With_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.html) | |

---


